# This is a Jinja2 template for the Ceph Cluster CRD (cluster.yaml)
# We deploy Ceph across the entire cluster using all available devices for OSDs.
apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  cephVersion:
    image: quay.io/ceph/ceph:v17.2.7
  dataDirHostPath: /var/lib/rook
  mon:
    count: 3
    allowMultiplePerNode: false
    # Add tolerations so monitors can run on master nodes
    placement:
      all:
        tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
        - key: node-role.kubernetes.io/master
          operator: Exists
          effect: NoSchedule
  storage:
    useAllNodes: {{ ceph_use_all_nodes }}
    useAllDevices: {{ ceph_use_all_devices }}
    deviceFilter: "" # Use all devices if 'useAllDevices' is true
    config:
      # If your nodes are hybrid (master/worker), you must tolerate the taints.
      monDevicePath: "/dev/disk/by-id/your-mon-device" # Replace with actual path if dedicated disk used for mon
      # Only use if you have specific disks you want to dedicate:
      # devices:
      # - name: "/dev/sdb"
